<TITLE> Format of Final Exam </TITLE>
<H2> Format of Final Exam </H2>

<p>
The final exam will be an in-class exam. It will be given on Monday, May
18, 5:00 - 6:50 in WWH 102. It will be open book and open notes.  No electronic
devices allowed.

<p>
The exam will be divided into two parts: web search engines and web mining.


<H4> Part I: Web Search Engines </H4>
<p>
Part I, Web Search Engines, will be worth 60% of the exam grade.  It will
cover the subjects listed below.  In this section I will ask only about any
issues that I have discussed in class. 
<UL>
<LI> General search engine architecture.  Lecture notes 1. 
Croft, Metzler, & Strohman Chap 2.
<LI> Crawling. Lecture notes 1. CM&S Chap 3 through 3.2.5 (pp. 31-40)
<LI> Document parsing. Lecture notes 2, "What is a term?". CM&S section 
4.3 through 4.3.4 (pp. 86-96)
<LI> Relevance. Lecture notes 2. CM&S section 7.1.2 (Vector model).
<LI> PageRank. Lecture notes on PageRank. CM&S section 4.5.2.
<LI> Inverted file (index) and compression. Lecture notes 3. CM&S Chap 5
through section 5.4.3 (pp. 125-148) 
<LI> Duplicates. Lecture notes 4. CM&S section 3.7. Manning, Raghavan,
and Sch&uuml;tze, section 19.6. 
<LI> Evaluation. Lecture notes 4. CM&S chap. 8 through 8.4.3. pp. 297-321
<LI> Sponsored links and auctions. Lecture notes 5. 
<A href="http://faculty.ist.psu.edu/jjansen/academic/pubs/jansen_overview_sponosored_search.pdf"> 
Sponsored search: an overview of the concept, history, and technology</A>
Bernard J. Jansen and Tracy Mullen, <em> International Journal of
Electronic Business,</em> 6:2 114-131. <br>
<LI> Collaborative filtering and recommender systems. Lecture notes 5.
<LI> Clustering. Lecture notes 6. CM&S section 6.3.3 and section 9.2
</UL>

<H4> Part II: Web Mining</H4>
<p>
Part II, Web Mining, will be worth 40% of the grade. For this part, you will 
choose ONE of the following six areas listed below 
and answer questions based on the specified readings. Please note: advance
preparation --- that is, carefully reading and thinking about the papers
in the area you choose --- is <em> essential </em> for this part of the exam.
If you have prepared the papers in your chosen area, the questions should be 
quite straightforward; if you are trying frantically to read them during the
exam, that will probably not work well. 

<p>
On the exam, I will only accept answers from ONE area.  If you answer questions
on part II from more than one area, I will choose one of these randomly,
grade you on that, and ignore the others.

<p>
Be sure to BRING A COPY of the papers in your area to the exam.  The questions
will refer to quite specific points in the paper, and you will need to have the
actual paper in hand to answer them. In this part of the exam, I may ask about
aspects of the paper that I did not discuss in class.

<p>
It might possibly be good strategy to prepare the papers in one back-up area 
in case you don't like the questions on your favorite area. I ADVISE STRONGLY
AGAINST PREPARING ALL THE AREAS UNLESS YOU HAVE A LOT OF FREE TIME BETWEEN NOW 
AND MAY 11TH. 

<p> Also: I will try to make the questions from the different areas of equal
difficulty.  But the papers themselves are of quite different length and
inherent difficulty; there is nothing I can do about that.  So you might want
to check out some of the areas that appeal to you and see which papers seem
easiest to you.

<p> Finally, quite a few of these papers do a statistical analysis of their 
results.  I am not assuming a knowledge of statistics, and therefore will not
ask about these statistical analyses.  
Generally, if one of the papers you 
are preparing draws on highly technical material outside the scope of this 
course, don't hesitate to check with me whether you really need to know this 
in detail; it is quite likely that I will not be asking you about it.

<p>
Specific papers are not yet entirely determined; these should be ready
soon.


<H4> Invisible Web </H4>
<A href="http://www.cs.cornell.edu/~lucja/publications/i03.pdf">
Google's Deep Web crawl </A> Madhavan et al. (2008)
Proceedings of the VLDB Endowment, 1(2), 1241-1252. <br>
<A href="http://pages.cs.wisc.edu/~heyeye/paper/Entity-crawl.pdf">
Crawling Deep Web Entity Pages </A>, He et al. (2013)
WSDM '13 Proceedings of the sixth ACM international conference on 
Web search and data mining, Pages 355-364 

<H4> Tables </H4>
<A href="http://dl.acm.org/citation.cfm?id=1935904">
 Web-scale table census and classification,</A>  
E. Crestan and P. Pantel, WSDM 2011.  <br>

<A href="http://www.eecs.umich.edu/~michjc/papers/webtables_vldb08.pdf">
WebTables: Exploring the Power of Tables on the Web,</A>
Michael Cafarella et al. PVLDB 2008

<H4> Sentiment Analysis </H4>
<A href="http://portal.acm.org/citation.cfm?id=1454712">
Opinion Mining and Sentiment Analysis </A>
Bo Pang and Lillian Lee (2008) Chap. 4 (pp. 23-60) <br>


<H4> Query Log Mining </H4>
<A href="http://didawiki.cli.di.unipi.it/lib/exe/fetch.php/wma/paper.pdf">
Mining query logs: Turning search usage data into knowledge</A>
Fabrizio Silvestri. Chaps. 4 and 5. <br>
<a href="http://maya.cs.depaul.edu/mobasher/papers/webminer-kais.pdf">
Data Preparation for Mining World Wide Web Browsing Patterns </A> 
Cooley, Mobasher, and Srivastava

<H4> Images </H4>
<A href="http://people.csail.mit.edu/torralba/tmp/tiny.pdf">
80 Million Tiny Images: A Large Dataset for Non-Parametric Object and
Scene Recognition,</A> Antonio Torralba, Rob Fergus, and William Freeman,
<em> IEEE PAMI </em> Nov. 2008, 30:1. <br>

<A href="http://www.springerlink.com/content/m8x1567r331g2405/">
A survey of browsing models for content based image retrieval </A>
Daniel Heesch  <em> Multimedia Tools and Applications</em> 40:2, 2008,
261-284.


<H4> Multi-lingual Web </H4>
<A href="http://trac.sketchengine.co.uk/raw-attachment/wiki/AK/Papers/2010_KilgReddyPomikalekAvinesh_LREC_CorpFactory.pdf">
A corpus factory for many languages</A> Adam Kilgariff et al., <em> LREC</em>
2010. <br>

<A href="http://borel.slu.edu/pub/wac3.pdf">
The Crubadan Project: Corpus building for under-resourced languages </A>
Kevin Scanell.

<H4> Information extraction </H4>
<A href="http://portal.acm.org/citation.cfm?id=1220874">
Preemptive information extraction using unrestricted relation discovery
</A> Yusuke Shinyama and Satoshi Sekine <br>
<A href="http://www.cs.cmu.edu/~tom/pubs/NELL_aaai15.pdf">
Never-Ending Learning</A> T. Mitchell et al. et al. AAAI-15.
